# speech-processing-pipeline

<p align="center">
    <img src="assets/pipeline.jpg" width="1080"/>
<p>

* æœ¬ä»“åº“è‡´åŠ›äºæ„å»ºé«˜è´¨é‡è¯­éŸ³æ•°æ®é›†çš„ pipelineï¼ŒåŒ…å«æ•°æ®æŠ“å–ã€äººå£°æŠ½å–ã€é™å™ªã€è½¬å½•ç­‰å…³é”®æ­¥éª¤ã€‚

* æˆ‘ä»¬åŸºäºè¿™å¥— pipeline æ¸…æ´—äº† 10,000+ å°æ—¶çš„å®Œæ•´æœ‰å£°ä¹¦éŸ³é¢‘ï¼Œæ”¯æŒè¯­éŸ³ç›¸å…³çš„å¤šç§ä¸‹æ¸¸ä»»åŠ¡ï¼šéŸ³é¢‘ç¼–ç å™¨ã€TTSã€Speech Generation ç­‰ç­‰ï¼Œæ¬¢è¿å¤§å®¶ç”¨äºç›¸å…³ç ”ç©¶ï¼


## ğŸ“š æ•°æ®ä¸‹è½½

1. ç¯å¢ƒå‡†å¤‡ï¼šæ•°æ®ä¸‹è½½ä¸»è¦ä¾èµ–äº `yt-dlp` åº“ã€‚

2. æ–‡ä»¶å‡†å¤‡ï¼šã€Šæœ‰å£°ä¹¦2.xlsxã€‹ è¡¨æ ¼ä¸­åŒ…å«äº†900å¤šæœ¬æ¥è‡ªäº Bilibili å’Œ Youtube çš„æœ‰å£°ä¹¦é“¾æ¥ï¼›

3. ä¸‹è½½ Bilibili / Youtube éŸ³é¢‘ï¼š

   * å¦‚æœå·²ç»ä¸‹è½½ä¸€éƒ¨åˆ†ä¹¦ç±ï¼Œå¯ä»¥å°†ä¹¦åæŒ‰è¡Œå†™å…¥ downloaded_book.txt ä¸­æ ‡è®°ï¼›

   * æ‰§è¡Œ `python download_youtube_book.py` ï¼Œè¯¥è„šæœ¬ä¼šä¸‹è½½è¡¨æ ¼ä¸­æœªä¸‹è½½çš„ Youtube å£°ä¹¦ï¼Œä¸‹è½½å†…å®¹ä¼šæŒ‰ç…§å¦‚ä¸‹æ ¼å¼å†™å…¥ `audiobook/` ç›®å½•ä¸­ï¼š

     ```bash
     ./
     â”œâ”€â”€ 150éƒ¨è‘—åçŸ­ç¯‡å°è¯´ç®€ä»‹
     â”‚Â Â  â”œâ”€â”€ 1.opus
     â”‚Â Â  â”œâ”€â”€ 2.opus
     â”‚Â Â  â””â”€â”€ 3.opus
     â”œâ”€â”€ ä¸€ç”Ÿ
     â”‚Â Â  â”œâ”€â”€ 1.opus
     â”‚Â Â  â””â”€â”€ 2.opus
     ...
     ```

   * åŒç†ï¼Œæ‰§è¡Œ `python download_bilibili_book.py` ï¼Œè¯¥è„šæœ¬ä¼šä¸‹è½½è¡¨æ ¼ä¸­æœªä¸‹è½½çš„ Bilibili å£°ä¹¦


## ğŸ¤– æ•°æ®æ¸…æ´—

æ¸…æ´—åŸåˆ™ï¼šé¢„è®­ç»ƒé˜¶æ®µçš„æ•°æ®å°½å¯èƒ½æ´—å¹²å‡€ï¼Œåé¢å¦‚æœæƒ³è¦å¢å¼ºæ¨¡å‹çš„é²æ£’æ€§ï¼Œå¯ä»¥å†å¯¹è®­ç»ƒæ•°æ®æ·»åŠ å™ªå£°ï¼Œè¿›è¡Œæ•°æ®å¢å¼ºã€‚è¿™æ ·çš„å¥½å¤„åœ¨äºé¢„è®­ç»ƒæ•°æ®è¿˜å¯ä»¥ç”¨æ¥åš TTS ä¹‹ç±»çš„å…¶ä»–ä»»åŠ¡ã€‚

> ASR ä»»åŠ¡çš„è¯æ•°æ®å¯ä»¥è„ä¸€ç‚¹ï¼Œå¢å¼ºé²æ£’æ€§ï¼ŒTTS ç›¸åï¼Œå¸Œæœ›ç”Ÿæˆå¹²å‡€çš„æ•°æ®ã€‚



### ç¯å¢ƒä¾èµ–

**å®‰è£… whisperx**

```bash
# æ–°å»ºç«‹ä¸€ä¸ªè™šæ‹Ÿç¯å¢ƒ
conda create -n whisperx python=3.10

# å®‰è£…ä¾èµ–é¡¹
pip install torch==2.0.0 torchaudio==2.0.0
pip install ctranslate2==4.4.0 numpy==1.24.3

pip install whisperx==3.2.0
```



**æœ¬åœ°è¿è¡Œpyannote**

ä¸‹è½½ [pyannote_model_wespeaker-voxceleb-resnet34-LM.bin](https://modelscope.cn/models/pyannote/wespeaker-voxceleb-resnet34-LM/resolve/master/pytorch_model.bin) å’Œ [pyannote_model_segmentation-3.0.bin](https://modelscope.cn/models/pyannote/segmentation-3.0/resolve/master/pytorch_model.bin) åˆ°æ ¹ç›®å½•ä¸‹çš„ `./models` ä¸­ï¼Œåˆ›å»º `./models/pyannote_diarization_config.yaml`

```yaml
version: 3.1.0

pipeline:
  name: pyannote.audio.pipelines.SpeakerDiarization
  params:
    clustering: AgglomerativeClustering
    embedding: models/pyannote_model_wespeaker-voxceleb-resnet34-LM.bin 
    embedding_batch_size: 32
    embedding_exclude_overlap: true
    segmentation: models/pyannote_model_segmentation-3.0.bin  
    segmentation_batch_size: 32

params:
  clustering:
    method: centroid
    min_cluster_size: 12
    threshold: 0.7045654963945799
  segmentation:
    min_duration_off: 0.0
```

> æ³¨æ„: æ–‡ä»¶è·¯å¾„å’Œå‘½åä¸èƒ½æ”¹ï¼ï¼ï¼

ä¿®æ”¹ whisperx æºç  `diarize.py`:
```python
import os
from pathlib import Path

def load_pipeline_from_pretrained(path_to_config: str | Path) -> Pipeline:
    path_to_config = Path(path_to_config)

    print(f"Loading pyannote pipeline from {path_to_config}...")

    cwd = Path.cwd().resolve() 

    cd_to = path_to_config.parent.parent.resolve()

    print(f"Changing working directory to {cd_to}")
    os.chdir(cd_to)

    pipeline = Pipeline.from_pretrained(path_to_config)

    print(f"Changing working directory back to {cwd}")
    os.chdir(cwd)

    return pipeline


class DiarizationPipeline:
    def __init__(
        self,
        model_name="models/pyannote_diarization_config.yaml",
        use_auth_token=None,
        device: Optional[Union[str, torch.device]] = "cpu",
    ):
        if isinstance(device, str):
            device = torch.device(device)
        # self.model = Pipeline.from_pretrained(model_name, use_auth_token=use_auth_token).to(device)
        self.model = load_pipeline_from_pretrained(model_name).to(device)
```



**å®‰è£… Demucs**

å»ºè®®ä»æºç å®‰è£…åˆ°æ ¹ç›®å½•ï¼š
```bash
git clone https://github.com/adefossez/demucs.git
cd demucs
pip install -e .
```



### éŸ³é¢‘å¢å¼º

åŸå§‹æŠ“å–çš„éŸ³é¢‘ä¸­å¯èƒ½åŒ…å«èƒŒæ™¯éŸ³ä¹æˆ–è€…å…¶ä»–çš„å™ªå£°ï¼Œä¸ºæ­¤æˆ‘ä»¬é¦–å…ˆéœ€è¦ä»ä¸­æŠ½å–å‡ºå¹²å‡€çš„äººå£°ã€‚



#### åˆ†ç¦»èƒŒæ™¯éŸ³ä¹

åˆ†ç¦»èƒŒæ™¯éŸ³ä¹é‡‡ç”¨ [Demucs4](https://github.com/adefossez/demucs) æ¨¡å‹ï¼Œç›¸æ¯”äº Stem2 å®ƒçš„æ•ˆæœæ›´å¥½ï¼Œä½†æ˜¯æ•ˆç‡ä¹Ÿä¼šæ…¢ä¸€ç‚¹ã€‚ä¸è¿‡å¥½å¤„åœ¨äº Demucs æ¨¡å‹å¯ä»¥ç›´æ¥æ”¯æŒé•¿éŸ³é¢‘çš„å¤„ç†ï¼Œä¸éœ€è¦åƒ Stem2 é‚£æ ·æ‰‹åŠ¨åˆ‡å‰²éŸ³é¢‘ï¼Œåˆ†æˆå°ä»½å¤„ç†ã€‚

éŸ³é¢‘å¤„ç†è„šæœ¬åœ¨ `data_collactor/demucs.py` ã€‚åœ¨æ‰§è¡Œè¯¥è„šæœ¬ä¹‹å‰ï¼Œä¸ºäº†åˆ©ç”¨å¤šå¼ GPUèµ„æºï¼Œéœ€è¦é¦–å…ˆå°†å¾…å¤„ç†æ–‡ä»¶æ‰‹åŠ¨åˆ’åˆ†æˆå¤šä»½ã€‚åŒæ—¶ä¹Ÿéœ€è¦æ³¨æ„ CPU çš„è´Ÿè½½ï¼Œå¯ä»¥é€šè¿‡ `lscpu` å‘½ä»¤æŸ¥çœ‹ NUMA èŠ‚ç‚¹çš„åˆ†åŒºæƒ…å†µã€‚æ ¹æ®åˆ†åŒºæ•°ç›®å’ŒGPUæ•°ç›®ï¼ˆä¸¤è€…æœ€å°çš„å€¼ï¼‰æ¥ç¡®å®šåˆ’åˆ†æ•°é‡ï¼š

```bash
python data_collactor/split_demucs_tasks.py
```

å¦‚æœå·²ç»å¤„ç†äº†ä¸€éƒ¨åˆ†æ–‡ä»¶ï¼Œå¯ä»¥å°†å¤„ç†åçš„ä¹¦åå†™å…¥ `processed_data/done.txt` æ–‡ä»¶ä¸­ã€‚

è¯¥è„šæœ¬ä¼šå°†å‰©ä½™çš„ä¹¦ååˆ†æˆå¤šä»½ï¼Œåˆ†åˆ«å†™å…¥ `./tasks` ç›®å½•ä¸‹çš„ txt æ–‡ä»¶ä¸­ã€‚



éšåï¼Œé€šè¿‡ `taskset` æŒ‡å®šè¿›ç¨‹è°ƒç”¨çš„ CPU æ ¸ï¼Œé¿å…ä¸åŒè¿›ç¨‹ä¹‹é—´äº§ç”Ÿèµ„æºäº‰æŠ¢çš„é—®é¢˜ï¼š

```bash
taskset -c 48-71 python -m data_collactor.demucs --gpu 2 --task-file tasks/gpu_2_tasks.txt
```

è¿™è¡Œå‘½ä»¤ä¼šå¯ç”¨ 48-71 çš„ CPU æ ¸ï¼Œåœ¨ GPU2 ä¸Šæ‰§è¡ŒèƒŒæ™¯éŸ³åˆ†ç¦»è„šæœ¬ï¼Œå¤„ç† tasks/gpu_2_tasks.txt ä¸­çš„æ–‡ä»¶ã€‚

> å°½ç®¡å¦‚æ­¤ï¼Œä¸€äº›æƒ…å†µä¸‹è¿›ç¨‹ä»ç„¶ä¼šå‡ºç° killed çš„é—®é¢˜ï¼Œå‡ºç°è¯¥é—®é¢˜ææœ‰å¯èƒ½æ˜¯é‡é‡‡æ ·éƒ¨åˆ†ä»£ç å¯¼è‡´çš„ã€‚
>
> å¦‚æœè¿™ç§æƒ…å†µå‡ºç°çš„è¯ï¼Œå°±é‡æ–°æ‰§è¡Œä¸Šè¿°å‘½ä»¤å³å¯ã€‚



**[Update]** é‡é‡‡æ ·å·²æ¢æˆ soxr è¿›è¡Œå¤„ç†ï¼Œæ•ˆæœæ›´ç¨³å®šã€‚å¦‚æœ GPU å†…å­˜å¾ˆè¶³ï¼Œä¹Ÿå¯ä»¥è€ƒè™‘ä½¿ç”¨ torchaudioï¼Œè¿™ä¸¤ä¸ªçš„å¤„ç†é€Ÿåº¦éƒ½å¾ˆå¿«ã€‚



#### é™å™ª

é™å™ªé‡‡ç”¨çš„æ˜¯ä¼°ç®—çš„ SNR å€¼ï¼Œå¦‚æœ SNR ä½äº 15dBï¼Œåˆ™ä¼šè°ƒç”¨é™å™ªæ¨¡å‹ã€‚è¿™é‡Œé€‰æ‹© [DeepFilterNet](https://github.com/Rikorose/DeepFilterNet) ä½œä¸ºé™å™ªæ¨¡å‹ã€‚

é™å™ªä¸éœ€è¦å¹¶è¡Œï¼Œå› ä¸ºç»å¤§å¤šæ–‡ä»¶çš„ SNR éƒ½è¿œé«˜äº 15dBï¼Œæœ‰å£°ä¹¦æ˜¯ä¸“ä¸šçš„å½•éŸ³è®¾å¤‡ï¼ŒéŸ³é¢‘è´¨é‡æ¯”è¾ƒå¥½ã€‚

è¿™ç§æƒ…å†µä¸‹ç›´æ¥è¿è¡Œ `denoise.py` å³å¯ï¼š

```bash
python data_collactor/denoise.py
```



### äººå£°åˆ†å‰²

#### éŸ³é¢‘åˆ‡åˆ†

äººå£°åˆ†å‰²æ²¡æœ‰ä½¿ç”¨ VADï¼Œè€Œæ˜¯ç›´æ¥é‡‡ç”¨ pyannote è¿›è¡Œç»†ç²’åº¦åˆ‡åˆ†ï¼Œæ ¸å¿ƒè„šæœ¬åœ¨ `data_collactor/segment.py`ã€‚

è€ƒè™‘åˆ° CPU çš„èµ„æºè°ƒç”¨ï¼Œè¿™é‡ŒåŒæ ·ä½¿ç”¨ `taskset` æ¥çº¦æŸå•ä¸ªè¿›ç¨‹è°ƒç”¨çš„ CPU æ ¸ã€‚

ä¸ºæ­¤ï¼Œé¦–å…ˆéœ€è¦å°†å¾…åˆ†å‰²éŸ³é¢‘åˆ’åˆ†æˆå¤šä»½ï¼Œå†™å…¥ file_lists ç›®å½•ä¸­ï¼Œæ¯”å¦‚ `file_lists/files_gpu_1.txt` ï¼Œæ¯ä¸€è¡Œæ˜¯å•ä¸ª vocals.wav çš„è·¯å¾„ã€‚

ç„¶åæ‰§è¡Œä¸‹é¢çš„å‘½ä»¤æ¥è¿›è¡Œäººå£°åˆ†å‰²ï¼š
```bash
taskset -c 0-23 python data_collactor/segment.py --gpu 0 --file-list file_lists/files_gpu_0.txt --root-dir processed_data/audiobook_vocal_20250120 --output temp_20250120_195855/segments_gpu_0.csv 2>&1 | tee segment_0.out
```

è¯¥è„šæœ¬ä¼šä»¥è¿½åŠ çš„å½¢å¼å‘æŒ‡å®š csv æ–‡ä»¶å†™å…¥åˆ†å‰²çš„ segment ä¿¡æ¯ï¼ŒåŒ…å«æºæ–‡ä»¶è·¯å¾„ä»¥åŠèµ·æ­¢æ—¶é—´æˆ³ã€‚



#### ç‰‡æ®µèšåˆ

ä¸Šè¿°è„šæœ¬çš„åˆ†å‰²ç»“æœæ˜¯æœ€å°ç‰‡æ®µï¼Œæ¥ä¸‹æ¥è¿˜éœ€è¦æ ¹æ®éœ€è¦å¯¹ç‰‡æ®µè¿›è¡Œèšåˆã€‚

èšåˆåŸç†å¾ˆç®€å•ï¼Œå¦‚æœç›¸é‚»çš„ç‰‡æ®µå±äºåŒä¸€ä¸ª Speakerï¼Œå¹¶ä¸”ç‰‡æ®µçš„æ—¶é—´é—´éš”ä½äºè®¾å®šçš„é˜ˆå€¼ï¼Œé‚£ä¹ˆå°±åˆå¹¶åˆ°ä¸€å¥è¯ä¸­ã€‚éœ€è¦æ³¨æ„ï¼Œä¸ºäº†å°½å¯èƒ½åˆ©ç”¨åˆ°å¤šçš„éŸ³é¢‘æ•°æ®ï¼Œæˆ‘ä»¬è¿˜è®¾ç½®äº†ä¸€ä¸ªæœ€é•¿éŸ³é¢‘é™åˆ¶ `max_len`ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨åˆå¹¶éŸ³é¢‘çš„æ—¶å€™ï¼Œå¦‚ä½•åˆå¹¶åçš„éŸ³é¢‘ç‰‡æ®µé•¿åº¦è¶…è¿‡äº† `max_len` ï¼Œé‚£ä¹ˆå°±ç»ˆæ­¢åˆå¹¶ï¼Œè®©åç»­éŸ³é¢‘å¼€å¯æ–°çš„ç‰‡æ®µã€‚

è¿™é‡Œ `max_len` çš„å‚æ•°å€¼è®¾ç½®ä¸º 300ï¼Œå¯¹åº”äº†é¢„è®­ç»ƒé˜¶æ®µçš„éŸ³é¢‘æœ€å¤§æ—¶é•¿ã€‚

è¿™éƒ¨åˆ†åŠŸèƒ½çš„å®ç°åœ¨è„šæœ¬ `data_collactor/merge_segments.py` ä¸­ï¼š

```bash
python data_collactor/merge_segments.py
```



æ‰§è¡Œè„šæœ¬ä¹‹åä¼šåœ¨ processed_data ç›®å½•ä¸‹çœ‹åˆ°å¾ˆå¤šé—´éš”é˜ˆå€¼å¯¹åº”çš„åˆ‡åˆ†ç‰‡æ®µæ—¶é•¿ç»Ÿè®¡ã€‚é€‰æ‹©åˆé€‚çš„é‚£ä¸ªæ–‡ä»¶ï¼Œæ‰§è¡Œä¸‹é¢çš„è„šæœ¬è¿›è¡Œåˆ‡å‰²ï¼Œä¿å­˜åˆ° processed_data ä¸‹ä¸€ä¸ªæ–°çš„äºŒçº§ç›®å½•ä¸­ã€‚

```BASH
python data_collactor/rewrite_segments.py
```



> ä¸ºäº†é€‰æ‹©åˆé€‚éŸ³é¢‘é—´éš”ï¼Œå¯ä»¥æ‰§è¡Œ plot.py æ¥ç»˜åˆ¶ä¸åŒéŸ³é¢‘åŒºé—´ä¸Šæ ·æœ¬çš„æ€»æ—¶é•¿ã€‚
>
> ç†æƒ³æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æœŸæœ›ä½äºæŸä¸ªdurationçš„åŒºé—´éŸ³é¢‘æ€»æ—¶é•¿å æ¯”ç›¸å¯¹è¾ƒä½ï¼ŒåŒæ—¶è¿™ä¸ª duration çš„é˜ˆå€¼å¯ä»¥æ¯”è¾ƒé«˜ã€‚æ¯”å¦‚ï¼Œæˆ‘ä»¬å¸Œæœ› 30s ä»¥å†…çš„éŸ³é¢‘æ€»æ—¶é•¿å æ¯”å¯ä»¥ä½äº10%ã€‚è¿™æ ·å¯ä»¥ç¡®ä¿æˆ‘ä»¬æœ‰è¶³å¤Ÿå¤šçš„é•¿éŸ³é¢‘ç”¨äºè®­ç»ƒã€‚



### éŸ³é¢‘è½¬å½•

éŸ³é¢‘è½¬å½•é‡‡ç”¨çš„æ˜¯ [faster-whisper-large-v3](https://modelscope.cn/models/keepitsimple/faster-whisper-large-v3) æ¨¡å‹ï¼Œè½¬å½•å®Œä¹‹åéœ€è¦è¿›è¡Œæ–‡æœ¬æ­£åˆ™åŒ–ã€‚å› ä¸ºç›´æ¥è½¬å½•çš„æ–‡æœ¬ä¸­å¯èƒ½åŒ…å«å¾ˆå¤šé˜¿æ‹‰ä¼¯æ•°å­—ä»¥åŠ%ç­‰ç‰¹æ®Šç¬¦å·ï¼Œè¿™äº›ä¼šå½±å“åˆ°åç»­çš„ CTC å¯¹é½ã€‚

æ–‡æœ¬æ­£åˆ™åŒ–ä¹‹åä½¿ç”¨ wav2vec2.0 æ¥è¿›è¡Œ CTC å¼ºåˆ¶å¯¹é½ã€‚è¿™é‡Œé€‰ç”¨[ä¸­æ–‡æ•°æ®é›†ä¸Šå¾®è°ƒåçš„ wav2vec æ¨¡å‹](https://modelscope.cn/models/jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn)ã€‚

æ•´ä¸ªéŸ³é¢‘è½¬å½•æµç¨‹å®ç°åœ¨ transcribe.py è„šæœ¬ä¸­ï¼Œæ‰§è¡Œä»¥ä¸‹æŒ‡ä»¤è¿è¡Œï¼š
```bash
CUDA_VISIBLE_DEVICES=0 python data_collactor/transcribe.py \
    --input_dir processed_data \
    --segments_file processed_data/segments_ag \
    --output_jsonl processed_data/transcriptions/output_gpu0.jsonl \
    --batch_size 64 \
    --compute_type float16
```

è¿™é‡Œæ˜¯æ‰‹åŠ¨å°†éœ€è¦å¤„ç†çš„éŸ³é¢‘ç‰‡æ®µåˆ†å‰²æˆäº†å¤šç‰‡ï¼Œå¹¶è¡Œå¤„ç†ã€‚

å¯ä»¥é€šè¿‡ä¸‹é¢è¿™è¡Œå‘½ä»¤ï¼Œå°†ç›®æ ‡æ–‡ä»¶ä¸­çš„å¾…å¤„ç†éŸ³é¢‘åˆ’åˆ†æˆå¤šä¸ªå¾…å¤„ç†åˆ—è¡¨ï¼Œ5300æ˜¯æ¯ä¸ªè¿›ç¨‹è¦å¤„ç†çš„æ–‡ä»¶æ•°ç›®:
```bash
find audiobook_vocal_20250212_segments_2.2_min_60_max_300/ -type f | sort | split -l 5300 - segments_
```


